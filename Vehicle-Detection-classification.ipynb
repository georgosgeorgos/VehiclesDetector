{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_p(data, name):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "def load_p(name):\n",
    "    with open(name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(img, converted, title1='Original', title2='Converted', cmap=\"gray\", flag1=False, flag2=False):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title(title1, fontsize=30)\n",
    "    ax2.imshow(converted, cmap=cmap)\n",
    "    ax2.set_title(title2, fontsize=30)\n",
    "    \n",
    "    if flag1 == True:\n",
    "        mpimg.imsave(\"output_images/\" + title1, img, format=\"jpg\")\n",
    "    if flag2 == True:\n",
    "        mpimg.imsave(\"output_images/\" + title2, converted, format=\"jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions for features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return gray\n",
    "    \n",
    "def hsvscale(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    return hsv\n",
    "\n",
    "def hlsscale(img):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    return hls\n",
    "\n",
    "def luvscale(img):\n",
    "    luv = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "    return luv\n",
    "\n",
    "def labscale(img):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    return lab\n",
    "\n",
    "def yuvscale(img):\n",
    "    yuv = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    return yuv\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color_space(img, flag=\"gray\"):\n",
    "    if flag==\"gray\":\n",
    "        res=grayscale(img)\n",
    "    elif flag==\"hsv\":\n",
    "        res=grayscale(img)\n",
    "    elif flag==\"hls\":\n",
    "        res=grayscale(img)\n",
    "    elif flag==\"luv\":\n",
    "        res=grayscale(img)\n",
    "    elif flag==\"lab\":\n",
    "        res=grayscale(img)\n",
    "    elif flag==\"yuv\":\n",
    "        res=grayscale(img)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spatial_features(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color_hist(img, nbins=32, bins_range=(0, 256), flag=False):\n",
    "    rh = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    gh = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    bh = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    \n",
    "    bin_edges = rh[1]\n",
    "    bin_centers = (bin_edges[1:]  + bin_edges[0:len(bin_edges)-1])/2\n",
    "    features = np.concatenate((rh[0], gh[0], bh[0]))\n",
    "    \n",
    "    if flag:\n",
    "        fig = plt.figure(figsize=(12,3))\n",
    "        plt.subplot(131)\n",
    "        plt.bar(bin_centers, rh[0])\n",
    "        #plt.bar(bin_centers, rhist[0])\n",
    "        plt.xlim(0, 256)\n",
    "        plt.title('R Histogram')\n",
    "        plt.subplot(132)\n",
    "        plt.bar(bin_centers, gh[0])\n",
    "        plt.xlim(0, 256)\n",
    "        plt.title('G Histogram')\n",
    "        plt.subplot(133)\n",
    "        plt.bar(bin_centers, bh[0])\n",
    "        plt.xlim(0, 256)\n",
    "        plt.title('B Histogram')\n",
    "        \n",
    "    return rh[0], gh[0], bh[0], bin_centers, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_hog(channel, pix_per_cell=16, cell_per_block=2, orient=11, flag=False):\n",
    "    \n",
    "    if flag:\n",
    "        features, hog_image = hog(channel, orientations=orient,\n",
    "                              pixels_per_cell=(pix_per_cell, pix_per_cell), \n",
    "                              cells_per_block=(cell_per_block, cell_per_block),\n",
    "                                  transform_sqrt=True, visualise=flag, feature_vector=False,\n",
    "                                  block_norm=\"L2-Hys\")\n",
    "        return hog_image, features\n",
    "    else:\n",
    "        features = hog(channel, orientations=orient,\n",
    "                      pixels_per_cell=(pix_per_cell, pix_per_cell), \n",
    "                      cells_per_block=(cell_per_block, cell_per_block),\n",
    "                          transform_sqrt=True, visualise=flag, feature_vector=False,\n",
    "                          block_norm=\"L2-Hys\")\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature for classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def routine_features(X, cars):\n",
    "    for car in cars:\n",
    "        #car=gaussian_blur(car, 5)\n",
    "        car=choose_color_space(car, \"yuv\")\n",
    "        channels=[car[:,:,0], car[:,:,1], car[:,:,2]]\n",
    "        features=[]\n",
    "        for c in channels:\n",
    "            f = f_hog(c)\n",
    "            f=f.ravel()\n",
    "            features.extend(f)\n",
    "        X.append(features)\n",
    "    return X\n",
    "\n",
    "def compute_features(vehicles, non_vehicles):\n",
    "    X = []\n",
    "    X=routine_features(X, vehicles)\n",
    "    X=routine_features(X, non_vehicles)\n",
    "    X=np.array(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def combine_features(img):\n",
    "#     gray=grayscale(img)\n",
    "#     rh, gh, bh, bin_centers, col_features=color_hist(img)\n",
    "#     hog_image, hog_features = f_hog(gray)\n",
    "#     features = np.vstack(feature_list).astype(np.float64)\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def routine(l, gti):\n",
    "    for name in gti:\n",
    "        img=cv2.imread(name)\n",
    "        img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        l.append(img)\n",
    "    return l\n",
    "def load_train_dataset():\n",
    "    vehicles=[]\n",
    "    non_vehicles=[]\n",
    "    \n",
    "    GTI=glob.glob(\"./non-vehicles/non-vehicles/GTI/*.png\")\n",
    "    Extra=glob.glob(\"./non-vehicles/non-vehicles/Extras/*.png\")\n",
    "    \n",
    "    non_vehicles=routine(non_vehicles, GTI)\n",
    "    non_vehicles=routine(non_vehicles, Extra)\n",
    "    \n",
    "    GTI_far=glob.glob(\"./vehicles/vehicles/GTI_Far/*.png\")\n",
    "    GTI_Left=glob.glob(\"./vehicles/vehicles/GTI_Left/*.png\")\n",
    "    GTI_MiddleClose=glob.glob(\"./vehicles/vehicles/GTI_MiddleClose/*.png\")\n",
    "    GTI_Right=glob.glob(\"./vehicles/vehicles/GTI_Right/*.png\")\n",
    "    KITTI=glob.glob(\"./vehicles/vehicles/KITTI_extracted/*.png\")\n",
    "    \n",
    "    vehicles=routine(vehicles, GTI_far)\n",
    "    vehicles=routine(vehicles, GTI_Left)\n",
    "    vehicles=routine(vehicles, GTI_MiddleClose)\n",
    "    vehicles=routine(vehicles, GTI_Right)\n",
    "    vehicles=routine(vehicles, KITTI)\n",
    "    \n",
    "    return vehicles, non_vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vehicles, non_vehicles=load_train_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=compute_features(vehicles, non_vehicles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17760, 1188)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np.hstack([np.ones(len(vehicles)), np.zeros(len(non_vehicles))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17760,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data={\"X\":X, \"Y\":Y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save_p(data, \"data.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=load_p(\"./data.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data[\"X\"]\n",
    "Y = data[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17760, 1188)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    state = np.random.randint(0, 100)\n",
    "    x_train, x_cv, y_train, y_cv = train_test_split(X_scaled, Y, test_size=0.2, random_state=state, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf=svm.SVC(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99311811811811812"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99099099099099097"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_cv, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"clf\"] = clf\n",
    "data[\"scaler\"] = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save_p(data, \"data.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = {\"svm_rbf\":svm.SVC(kernel='rbf')}\n",
    "parameters = {\"svm_rbf\":{\"C\" : [0.1, 0.5, 1, 5, 10], \"gamma\" : [0.1, 0.5, 1, 3]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_routine(clf,parameters):\n",
    "    \n",
    "    grid = GridSearchCV(clf, parameters, scoring=\"accuracy\")\n",
    "    grid.fit(x_train,y_train)\n",
    "    clf = grid.best_estimator_ \n",
    "    train_score = clf.score(x_train,y_train)\n",
    "    cv_score = cross_val_score(clf, x_cv, y_cv, cv=3, scoring = \"accuracy\").mean()\n",
    "    \n",
    "    return clf, train_score, cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "d = []\n",
    "for c in [\"svm_rbf\"]:\n",
    "    clf=classifiers[c]\n",
    "    par=parameters[c]\n",
    "    clf_best, train_score , cv_score = grid_routine(clf, par)\n",
    "    d[c] = [clf_best, train_score , cv_score]\n",
    "end=time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread(\"./test_images/test4.jpg\")\n",
    "img_copy = img.copy()\n",
    "#img_copy[:n//2,:,:] = 0\n",
    "n, m, k = img_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def windows(boxes, s=\"s\", flag=False):\n",
    "    \n",
    "    n, m, k = img_copy.shape\n",
    "    k=n//2\n",
    "    step=0.5\n",
    "    \n",
    "    if s == \"s\":\n",
    "        size=n//12\n",
    "        n_y= (n//2 // size)\n",
    "        n_x= (m // size)\n",
    "        range_y=[0.0,1.0,2.0] \n",
    "        range_x=[i for i in np.arange(5, n_x, step)]\n",
    "    elif s == \"m\":\n",
    "        size=n//6\n",
    "        n_y= (n//2 // size)\n",
    "        n_x= (m // size)\n",
    "        range_y=[i for i in np.arange(0, n_y, step)] \n",
    "        range_x=[i for i in np.arange(2, n_x, step)]\n",
    "    elif s == \"l\":\n",
    "        size=n//4\n",
    "        n_y= (n//2 // size)\n",
    "        n_x= (m // size)\n",
    "        range_y=[i for i in np.arange(0, n_y, step)] \n",
    "        range_x=[i for i in np.arange(0, n_x, step)]\n",
    "        \n",
    "    if s==\"s\":\n",
    "        color=(0,0,255)\n",
    "    elif s==\"m\":\n",
    "        color=(255,0,0)\n",
    "    elif s==\"l\":\n",
    "        color=(0,255,0)\n",
    "    \n",
    "    for y in range_y:\n",
    "        for x in range_x:\n",
    "            xb, yb = int(x*size), int(k+size*(y+1))\n",
    "            xu, yu = int(size*(x+1)), int(k+size*(y))\n",
    "            bottom_left=(xb, yb)\n",
    "            upper_right=(xu, yu)\n",
    "            if flag:\n",
    "                z=cv2.rectangle(img_copy,bottom_left,upper_right,color, 2)\n",
    "            boxes.append((bottom_left, upper_right))\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_box(img, box):\n",
    "    xb, yb =box[0]\n",
    "    xu, yu =box[1]\n",
    "    img_box=img[yu:yb, xb:xu]\n",
    "    return img_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_box=select_box(img, boxes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boxes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sizes=[\"s\", \"m\", \"l\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for s in sizes:\n",
    "    boxes=windows(boxes, s, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.imshow(img_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hog_features=features.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heatmap = threshold(heatmap, 2)\n",
    "labels = label(heatmap)\n",
    "print(labels[1], 'cars found')\n",
    "plt.imshow(labels[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "# Read in the last image above\n",
    "image = mpimg.imread('img105.jpg')\n",
    "# Draw bounding boxes on a copy of the image\n",
    "draw_img = draw_labeled_bboxes(np.copy(image), labels)\n",
    "# Display the image\n",
    "plt.imshow(draw_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot3d(pixels, colors_rgb,\n",
    "        axis_labels=list(\"RGB\"), axis_limits=((0, 255), (0, 255), (0, 255))):\n",
    "    \"\"\"Plot pixels in 3D.\"\"\"\n",
    "\n",
    "    # Create figure and 3D axes\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = Axes3D(fig)\n",
    "\n",
    "    # Set axis limits\n",
    "    ax.set_xlim(*axis_limits[0])\n",
    "    ax.set_ylim(*axis_limits[1])\n",
    "    ax.set_zlim(*axis_limits[2])\n",
    "\n",
    "    # Set axis labels and sizes\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14, pad=8)\n",
    "    ax.set_xlabel(axis_labels[0], fontsize=16, labelpad=16)\n",
    "    ax.set_ylabel(axis_labels[1], fontsize=16, labelpad=16)\n",
    "    ax.set_zlabel(axis_labels[2], fontsize=16, labelpad=16)\n",
    "\n",
    "    # Plot pixel values with colors given in colors_rgb\n",
    "    ax.scatter(\n",
    "        pixels[:, :, 0].ravel(),\n",
    "        pixels[:, :, 1].ravel(),\n",
    "        pixels[:, :, 2].ravel(),\n",
    "        c=colors_rgb.reshape((-1, 3)), edgecolors='none')\n",
    "\n",
    "    return ax  # return Axes3D object for further manipulation\n",
    "\n",
    "\n",
    "# Read a color image\n",
    "img = cv2.imread(\"000275.png\")\n",
    "\n",
    "# Select a small fraction of pixels to plot by subsampling it\n",
    "scale = max(img.shape[0], img.shape[1], 64) / 64  # at most 64 rows and columns\n",
    "img_small = cv2.resize(img, (np.int(img.shape[1] / scale), np.int(img.shape[0] / scale)), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# Convert subsampled image to desired color space(s)\n",
    "img_small_RGB = cv2.cvtColor(img_small, cv2.COLOR_BGR2RGB)  # OpenCV uses BGR, matplotlib likes RGB\n",
    "img_small_HSV = cv2.cvtColor(img_small, cv2.COLOR_BGR2HSV)\n",
    "img_small_rgb = img_small_RGB / 255.  # scaled to [0, 1], only for plotting\n",
    "\n",
    "# Plot and show\n",
    "plot3d(img_small_RGB, img_small_rgb)\n",
    "plt.show()\n",
    "\n",
    "plot3d(img_small_HSV, img_small_rgb, axis_labels=list(\"HSV\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
